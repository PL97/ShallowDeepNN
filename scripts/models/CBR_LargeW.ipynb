{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratifySample(features, labels, bs):\n",
    "    batches = []\n",
    "    pos = np.where(labels == 1)[0]\n",
    "    neg = np.where(labels == 0)[0]\n",
    "    random.shuffle(pos)\n",
    "    random.shuffle(neg)\n",
    "\n",
    "    pos_num = len(pos)\n",
    "    neg_num = len(neg)\n",
    "\n",
    "    print(\"positive:{}\\tnegative:{}\".format(pos_num, neg_num))\n",
    "\n",
    "    p_r = pos_num / (neg_num + pos_num)\n",
    "    n_r = 1-p_r\n",
    "\n",
    "\n",
    "    bs_p = math.ceil(bs * p_r)\n",
    "    bs_n = bs - bs_p\n",
    "\n",
    "    batches_p = math.floor(pos_num/bs_p)\n",
    "    batches_n = math.floor(neg_num/bs_n)\n",
    "\n",
    "\n",
    "    for i in range(min(batches_p, batches_n)):\n",
    "        bt_p_features = features[pos[i*bs_p : (i+1)*bs_p]]\n",
    "        bt_p_labels = labels[pos[i*bs_p : (i+1)*bs_p]]\n",
    "\n",
    "        bt_n_features = features[neg[i*bs_n : (i+1)*bs_n]]\n",
    "        bt_n_labels = labels[neg[i*bs_n : (i+1)*bs_n]]\n",
    "\n",
    "        bt_comb_features = np.concatenate((bt_p_features, bt_n_features), axis = 0)\n",
    "        bt_comb_labels = np.concatenate((bt_p_labels, bt_n_labels), axis = 0)\n",
    "\n",
    "        idx = list(range(bs))\n",
    "        random.shuffle(idx)\n",
    "        bt_comb_features, bt_comb_labels = bt_comb_features[idx], bt_comb_labels[idx]\n",
    "        bt_comb_features, bt_comb_labels = map(torch.tensor, (bt_comb_features, bt_comb_labels))\n",
    "        batches.append((bt_comb_features, bt_comb_labels))\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBR(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, stride=1, kernel_size=3):\n",
    "        super(CBR, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride)\n",
    "        self.bn = nn.BatchNorm2d(out_channel)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        return x\n",
    "    \n",
    "class CBR_LargeW(nn.Module):\n",
    "    def __init__(self, input_channels=3, kernel_size=7, stride=1):\n",
    "        super(CBR_LargeW, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.CBR1 = CBR(input_channels, self.in_channels, self.stride, self.kernel_size)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2))\n",
    "        \n",
    "        self.CBR2 = CBR(self.in_channels, self.in_channels*2, self.stride, self.kernel_size)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2))\n",
    "        \n",
    "        self.CBR3 = CBR(self.in_channels*2, self.in_channels*4, self.stride, self.kernel_size)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2))\n",
    "        \n",
    "        self.CBR4 = CBR(self.in_channels*4, self.in_channels*8, self.stride, self.kernel_size)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2))\n",
    "        \n",
    "        \n",
    "        # classifier\n",
    "        self.fc = nn.Linear(self.in_channels*8, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.CBR1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.CBR2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.CBR3(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.CBR4(x)\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 224, 224, 3) (700,)\n",
      "0.0 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({1: 174, 0: 526})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA = np.load(\"../../../dataset/diabetic-retinopathy-npy/Messidor1/data.npy\")\n",
    "LABEL = np.load(\"../../../dataset/diabetic-retinopathy-npy/Messidor1/label.npy\")\n",
    "LABEL[LABEL < 3] = 0\n",
    "LABEL[LABEL >=3 ] = 1\n",
    "\n",
    "\n",
    "print(DATA.shape, LABEL.shape)\n",
    "print(np.min(DATA), np.max(DATA))\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "Counter(LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 224, 224, 3) (140, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(DATA, LABEL, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "data = {}\n",
    "label = {}\n",
    "data['train'] = X_train\n",
    "label['train'] = y_train\n",
    "data['val'] = X_test\n",
    "label['val'] = y_test\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 560, 'val': 140}\n"
     ]
    }
   ],
   "source": [
    "# convert to PIL image\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "PIL_data = {x:[Image.fromarray(np.uint8(data[x][i] * 255)).convert('RGB') for i in range(data[x].shape[0])] for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(PIL_data[x]) for x in ['train', 'val']}\n",
    "\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "#         transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = {x: torch.stack([data_transforms[x](PIL_data[x][i]) for i in range(len(PIL_data[x]))]) for x in ['train', 'val']}\n",
    "label_tensor = {x: torch.Tensor(label[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TensorDataset(data_tensor['train'], label_tensor['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive:133\tnegative:427\n",
      "positive:41\tnegative:99\n"
     ]
    }
   ],
   "source": [
    "# ds = {x: TensorDataset(data_tensor[x], label_tensor[x]) for x in ['train', 'val']}\n",
    "# dl = {x: DataLoader(ds[x], batch_size=32, shuffle=True, num_workers=8) for x in ['train', 'val']}\n",
    "\n",
    "bs = 8\n",
    "dl = {x: stratifySample(data_tensor[x], label_tensor[x], bs) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dl['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(output, target, criterion):\n",
    "    \n",
    "    pos_target = target[target == 1]\n",
    "    pos_output = output[target == 1]\n",
    "    \n",
    "    neg_target = target[target == 0]\n",
    "    neg_output = output[target == 0]\n",
    "    \n",
    "    p_loss = criterion(pos_output, pos_target)/pos_target.shape[0]\n",
    "    n_loss = criterion(neg_output, neg_target)/neg_target.shape[0]\n",
    "    \n",
    "    loss = torch.max(p_loss, n_loss)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def train_model(dataloaders, dataset_sizes, model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                labels = labels.long()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "            \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = my_loss(outputs, labels, criterion)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train' and scheduler != None:\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBR_LargeW(\n",
      "  (CBR1): CBR(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (pool1): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (CBR2): CBR(\n",
      "    (conv): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (pool2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (CBR3): CBR(\n",
      "    (conv): Conv2d(128, 256, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (pool3): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (CBR4): CBR(\n",
      "    (conv): Conv2d(256, 512, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (pool4): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_ft = CBR_LargeW()\n",
    "print(model_ft)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "exp_lr_scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 0.2705 Acc: 0.2554\n",
      "val Loss: 0.1999 Acc: 0.2786\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.2102 Acc: 0.2429\n",
      "val Loss: 0.1708 Acc: 0.2714\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.1980 Acc: 0.2411\n",
      "val Loss: 0.1655 Acc: 0.2714\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.2050 Acc: 0.2518\n",
      "val Loss: 0.1820 Acc: 0.2929\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.1967 Acc: 0.2446\n",
      "val Loss: 0.1673 Acc: 0.2857\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.1980 Acc: 0.2536\n",
      "val Loss: 0.1937 Acc: 0.2786\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.1969 Acc: 0.2786\n",
      "val Loss: 0.2194 Acc: 0.2786\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.1952 Acc: 0.2589\n",
      "val Loss: 0.1998 Acc: 0.2786\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.2075 Acc: 0.2679\n",
      "val Loss: 0.1859 Acc: 0.2929\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.2069 Acc: 0.2661\n",
      "val Loss: 0.2014 Acc: 0.2786\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.1961 Acc: 0.2857\n",
      "val Loss: 0.2007 Acc: 0.2786\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.2001 Acc: 0.2804\n",
      "val Loss: 0.1549 Acc: 0.3429\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.1941 Acc: 0.3143\n",
      "val Loss: 0.2198 Acc: 0.2786\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.2030 Acc: 0.2768\n",
      "val Loss: 0.1836 Acc: 0.3071\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.1913 Acc: 0.3054\n",
      "val Loss: 0.1870 Acc: 0.2857\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.1852 Acc: 0.2946\n",
      "val Loss: 0.1719 Acc: 0.3429\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.1874 Acc: 0.3179\n",
      "val Loss: 0.1773 Acc: 0.2857\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.1848 Acc: 0.3089\n",
      "val Loss: 0.1879 Acc: 0.2857\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.1862 Acc: 0.3196\n",
      "val Loss: 0.1659 Acc: 0.3071\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.1882 Acc: 0.3161\n",
      "val Loss: 0.1623 Acc: 0.3214\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.1840 Acc: 0.3554\n",
      "val Loss: 0.1511 Acc: 0.3286\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.1874 Acc: 0.3196\n",
      "val Loss: 0.1445 Acc: 0.3500\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.1897 Acc: 0.3446\n",
      "val Loss: 0.1793 Acc: 0.3429\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.1956 Acc: 0.3196\n",
      "val Loss: 0.1633 Acc: 0.3286\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.1814 Acc: 0.3571\n",
      "val Loss: 0.1627 Acc: 0.3357\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.1906 Acc: 0.3143\n",
      "val Loss: 0.1600 Acc: 0.3214\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.1822 Acc: 0.3232\n",
      "val Loss: 0.1624 Acc: 0.3214\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.1887 Acc: 0.3750\n",
      "val Loss: 0.1635 Acc: 0.3429\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.1851 Acc: 0.3786\n",
      "val Loss: 0.1526 Acc: 0.3500\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.1880 Acc: 0.3625\n",
      "val Loss: 0.1469 Acc: 0.3500\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.2071 Acc: 0.3339\n",
      "val Loss: 0.1749 Acc: 0.2857\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.1890 Acc: 0.3571\n",
      "val Loss: 0.1488 Acc: 0.3786\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.1896 Acc: 0.2982\n",
      "val Loss: 0.1447 Acc: 0.3857\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.1809 Acc: 0.3732\n",
      "val Loss: 0.1507 Acc: 0.3643\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.1867 Acc: 0.3875\n",
      "val Loss: 0.1754 Acc: 0.3214\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 0.1816 Acc: 0.3964\n",
      "val Loss: 0.1623 Acc: 0.4143\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 0.1816 Acc: 0.4125\n",
      "val Loss: 0.1570 Acc: 0.3429\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 0.1898 Acc: 0.3661\n",
      "val Loss: 0.1413 Acc: 0.3714\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 0.1750 Acc: 0.3929\n",
      "val Loss: 0.1451 Acc: 0.3714\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 0.1825 Acc: 0.4179\n",
      "val Loss: 0.1494 Acc: 0.3929\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 0.1829 Acc: 0.4339\n",
      "val Loss: 0.1347 Acc: 0.3786\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 0.1869 Acc: 0.3964\n",
      "val Loss: 0.1447 Acc: 0.3714\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 0.1928 Acc: 0.3911\n",
      "val Loss: 0.1410 Acc: 0.3929\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 0.1870 Acc: 0.4089\n",
      "val Loss: 0.1659 Acc: 0.4286\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 0.1807 Acc: 0.4089\n",
      "val Loss: 0.1537 Acc: 0.3429\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 0.1805 Acc: 0.3893\n",
      "val Loss: 0.1430 Acc: 0.4000\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 0.1846 Acc: 0.4125\n",
      "val Loss: 0.2142 Acc: 0.4714\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 0.1830 Acc: 0.4196\n",
      "val Loss: 0.1424 Acc: 0.4143\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 0.1829 Acc: 0.4018\n",
      "val Loss: 0.1509 Acc: 0.4000\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 0.1826 Acc: 0.4393\n",
      "val Loss: 0.1730 Acc: 0.3643\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 0.1829 Acc: 0.4071\n",
      "val Loss: 0.1489 Acc: 0.3857\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 0.1722 Acc: 0.4054\n",
      "val Loss: 0.1445 Acc: 0.4071\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 0.1740 Acc: 0.4554\n",
      "val Loss: 0.1529 Acc: 0.4357\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 0.1730 Acc: 0.4339\n",
      "val Loss: 0.1572 Acc: 0.4286\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 0.1826 Acc: 0.4304\n",
      "val Loss: 0.1418 Acc: 0.3714\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 0.1805 Acc: 0.4339\n",
      "val Loss: 0.1529 Acc: 0.3714\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 0.1742 Acc: 0.4607\n",
      "val Loss: 0.2041 Acc: 0.4714\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 0.1784 Acc: 0.4571\n",
      "val Loss: 0.1414 Acc: 0.4143\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 0.1783 Acc: 0.4500\n",
      "val Loss: 0.1735 Acc: 0.4786\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 0.1867 Acc: 0.4143\n",
      "val Loss: 0.1687 Acc: 0.4357\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 0.1758 Acc: 0.4375\n",
      "val Loss: 0.1958 Acc: 0.4500\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 0.1771 Acc: 0.4232\n",
      "val Loss: 0.2332 Acc: 0.4643\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 0.1758 Acc: 0.4429\n",
      "val Loss: 0.2984 Acc: 0.4643\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 0.1759 Acc: 0.4375\n",
      "val Loss: 0.1459 Acc: 0.3357\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.1669 Acc: 0.4446\n",
      "val Loss: 0.1662 Acc: 0.4357\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.1661 Acc: 0.4661\n",
      "val Loss: 0.1677 Acc: 0.4429\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.1713 Acc: 0.4571\n",
      "val Loss: 0.1616 Acc: 0.3643\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.1709 Acc: 0.4732\n",
      "val Loss: 0.1525 Acc: 0.3857\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 0.1743 Acc: 0.4768\n",
      "val Loss: 0.1705 Acc: 0.4786\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 0.1775 Acc: 0.4607\n",
      "val Loss: 0.1448 Acc: 0.3857\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 0.1715 Acc: 0.4643\n",
      "val Loss: 0.1479 Acc: 0.3786\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 0.1773 Acc: 0.4696\n",
      "val Loss: 0.1848 Acc: 0.3286\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 0.1707 Acc: 0.4536\n",
      "val Loss: 0.1887 Acc: 0.3286\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 0.1666 Acc: 0.4893\n",
      "val Loss: 0.1888 Acc: 0.4143\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 0.1689 Acc: 0.4911\n",
      "val Loss: 0.1762 Acc: 0.4714\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 0.1632 Acc: 0.5089\n",
      "val Loss: 0.1713 Acc: 0.3714\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 0.1609 Acc: 0.4982\n",
      "val Loss: 0.1638 Acc: 0.4000\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 0.1632 Acc: 0.5196\n",
      "val Loss: 0.1930 Acc: 0.4786\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 0.1659 Acc: 0.4839\n",
      "val Loss: 0.1548 Acc: 0.4286\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 0.1632 Acc: 0.4946\n",
      "val Loss: 0.2471 Acc: 0.4929\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 0.1694 Acc: 0.4946\n",
      "val Loss: 0.2208 Acc: 0.4286\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 0.1569 Acc: 0.5107\n",
      "val Loss: 0.1939 Acc: 0.4143\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 0.1725 Acc: 0.5125\n",
      "val Loss: 0.1543 Acc: 0.3929\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "train Loss: 0.1645 Acc: 0.5143\n",
      "val Loss: 0.1991 Acc: 0.3000\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "train Loss: 0.1698 Acc: 0.5143\n",
      "val Loss: 0.1605 Acc: 0.4143\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "train Loss: 0.1536 Acc: 0.5232\n",
      "val Loss: 0.3877 Acc: 0.5000\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "train Loss: 0.1532 Acc: 0.5446\n",
      "val Loss: 0.1941 Acc: 0.4214\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "train Loss: 0.1603 Acc: 0.5411\n",
      "val Loss: 0.2137 Acc: 0.3357\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "train Loss: 0.1644 Acc: 0.5089\n",
      "val Loss: 0.1525 Acc: 0.4143\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "train Loss: 0.1600 Acc: 0.5286\n",
      "val Loss: 0.2167 Acc: 0.4786\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "train Loss: 0.1504 Acc: 0.5625\n",
      "val Loss: 0.2615 Acc: 0.3429\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "train Loss: 0.1582 Acc: 0.5643\n",
      "val Loss: 0.1708 Acc: 0.4500\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "train Loss: 0.1533 Acc: 0.5643\n",
      "val Loss: 0.2783 Acc: 0.4714\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "train Loss: 0.1606 Acc: 0.5714\n",
      "val Loss: 0.2337 Acc: 0.4500\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "train Loss: 0.1584 Acc: 0.5393\n",
      "val Loss: 0.2456 Acc: 0.3214\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "train Loss: 0.1581 Acc: 0.5411\n",
      "val Loss: 0.2023 Acc: 0.3643\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "train Loss: 0.1498 Acc: 0.5875\n",
      "val Loss: 0.2149 Acc: 0.4714\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "train Loss: 0.1510 Acc: 0.5625\n",
      "val Loss: 0.2717 Acc: 0.3071\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1454 Acc: 0.5786\n",
      "val Loss: 0.1959 Acc: 0.3929\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "train Loss: 0.1463 Acc: 0.5732\n",
      "val Loss: 0.2044 Acc: 0.5214\n",
      "\n",
      "Training complete in 10m 12s\n",
      "Best val Acc: 0.521429\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(dl, dataset_sizes, model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"saved_models/CBR_LargeW.pt\"\n",
    "torch.save(model_ft.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
